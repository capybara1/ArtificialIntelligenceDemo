{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import skopt\n",
    "from skopt.utils import use_named_args\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "from shutil import rmtree\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_PATH = os.path.join('.', 'logs', 'fit', 'petimages')\n",
    "MODEL_FILE_NAME = 'keras_petimages_cnn.model'\n",
    "DATA_X_PATH = 'petimages.x.pickle'\n",
    "DATA_Y_PATH = 'petimages.y.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    pickle_in = open(path, 'rb')\n",
    "    result = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(DATA_X_PATH):\n",
    "    raise f'Data file \"{DATA_Y_PATH}\" does not exist' \\\n",
    "        + 'download petimage dataset from kaggle and' \\\n",
    "        + 'use tools/load_image_data.py to perpare the data'\n",
    "if not os.path.isfile(DATA_Y_PATH):\n",
    "    raise f'Data file \"{DATA_Y_PATH}\" does not exist' \\\n",
    "        + 'download petimage dataset from kaggle and' \\\n",
    "        + 'use tools/load_image_data.py to perpare the data'\n",
    "x = load_data(DATA_X_PATH)\n",
    "y = load_data(DATA_Y_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_pos = random.randint(1, x.shape[0])\n",
    "print(f'Image at {sample_pos}')\n",
    "sample_image = x[sample_pos - 1]\n",
    "if len(sample_image.shape) == 3 and sample_image.shape[2] == 1:\n",
    "    sample_image = sample_image.reshape(sample_image.shape[:2])\n",
    "plt.imshow(sample_image, cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Data\n",
    "Data is already normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model(learning_rate, num_conv_layers, exp_num_filters, kernel_radius, num_dense_layers, num_dense_nodes, activation):\n",
    "    kernel_shape = tuple([kernel_radius * 2 - 1] * 2)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(2**exp_num_filters, kernel_shape, input_shape=x.shape[1:]))\n",
    "    model.add(tf.keras.layers.Activation(activation))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    for l in range(num_conv_layers - 1):\n",
    "        model.add(tf.keras.layers.Conv2D(2**(exp_num_filters + l), kernel_shape))\n",
    "        model.add(tf.keras.layers.Activation(activation))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for i in range(num_dense_layers - 1):\n",
    "        model.add(tf.keras.layers.Dense(num_dense_nodes, activation=activation))\n",
    "    if num_dense_layers > 1:\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Dense(2, activation = tf.nn.softmax))\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate),\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Verify Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dir_path(learning_rate, num_conv_layers, exp_num_filters, kernel_radius, num_dense_layers, num_dense_nodes, activation):\n",
    "    time_stamp = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    log_dir_name_pattern = \"lr{0:.0e}_cl{1}_e{2}_k{3}x{3}_dl{4}_n{5}_a{6}_{7}\"\n",
    "    kernel_width = kernel_radius * 2 - 1\n",
    "    log_dir_name = log_dir_name_pattern.format(learning_rate,\n",
    "                                               num_conv_layers,\n",
    "                                               exp_num_filters,\n",
    "                                               kernel_width,\n",
    "                                               num_dense_layers,\n",
    "                                               num_dense_nodes,\n",
    "                                               activation,\n",
    "                                               time_stamp)\n",
    "    log_dir = os.path.join(LOGS_PATH, log_dir_name)\n",
    "\n",
    "    return log_dir\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_model(learning_rate, num_conv_layers, exp_num_filters, kernel_radius, num_dense_layers, num_dense_nodes, activation):\n",
    "    model = create_model(learning_rate=learning_rate,\n",
    "                         num_conv_layers=num_conv_layers,\n",
    "                         exp_num_filters=exp_num_filters,\n",
    "                         kernel_radius=kernel_radius, \n",
    "                         num_dense_layers=num_dense_layers,\n",
    "                         num_dense_nodes=num_dense_nodes,\n",
    "                         activation=activation)\n",
    "    \n",
    "    log_dir = log_dir_path(learning_rate,\n",
    "                           num_conv_layers,\n",
    "                           exp_num_filters,\n",
    "                           kernel_radius, \n",
    "                           num_dense_layers,\n",
    "                           num_dense_nodes,\n",
    "                           activation)\n",
    "    \n",
    "    tensor_board_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "                                                           histogram_freq=1)\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                               patience=2,\n",
    "                                                               restore_best_weights=True)\n",
    "   \n",
    "    history = model.fit(x=x,\n",
    "                        y=y,\n",
    "                        validation_split=0.3,\n",
    "                        epochs=20, \n",
    "                        callbacks=[tensor_board_callback,\n",
    "                                   early_stopping_callback])\n",
    "    accuracy = history.history['val_accuracy'][early_stopping_callback.stopped_epoch]\n",
    "    \n",
    "    return model, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "if os.path.isdir(LOGS_PATH):\n",
    "    rmtree(LOGS_PATH, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_parameters = [1e-3, 2, 5, 3, 2, 128, 'relu']\n",
    "model, accuracy = fit_model(*initial_parameters)\n",
    "print()\n",
    "print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "del model\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimiziation\n",
    "Using Bayesian Optimiziation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_learning_rate = skopt.space.Real(low=1e-6, high=1e-1, prior='log-uniform', name='learning_rate')\n",
    "dim_num_conv_layers = skopt.space.Integer(low=1, high=3, name='num_conv_layers')\n",
    "dim_exp_num_filters = skopt.space.Integer(low=3, high=7, name='exp_num_filters')\n",
    "dim_kernel_radius = skopt.space.Integer(low=2, high=4, name='kernel_radius')\n",
    "dim_num_dense_layers = skopt.space.Integer(low=0, high=3, name='num_dense_layers')\n",
    "dim_num_dense_nodes = skopt.space.Integer(low=5, high=512, name='num_dense_nodes')\n",
    "dim_activation = skopt.space.Categorical(categories=['relu', 'sigmoid'], name='activation')\n",
    "dimensions = [\n",
    "    dim_learning_rate,\n",
    "    dim_num_conv_layers,\n",
    "    dim_exp_num_filters,\n",
    "    dim_kernel_radius,\n",
    "    dim_num_dense_layers,\n",
    "    dim_num_dense_nodes,\n",
    "    dim_activation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\n",
    "    'accuracy': [],\n",
    "    'learning_rate': [],\n",
    "    'num_conv_layers': [],\n",
    "    'exp_num_filters': [],\n",
    "    'num_dense_layers': [],\n",
    "    'num_dense_nodes': [],\n",
    "    'activation': []\n",
    "}\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(learning_rate, num_conv_layers, exp_num_filters, kernel_radius, num_dense_layers, num_dense_nodes, activation):\n",
    "    \n",
    "    print(f'run {len(runs[\"accuracy\"]) + 1}')\n",
    "    print()\n",
    "    print('Learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('Number of convolution layers:', num_conv_layers)\n",
    "    print('Exponent of size of first convolution layer:', exp_num_filters)\n",
    "    print('Kernel radius:', kernel_radius)\n",
    "    print('Number of dense layers:', num_dense_layers)\n",
    "    print('Number of dense nodes:', num_dense_nodes)\n",
    "    print('Activation function:', activation)\n",
    "    print()\n",
    "    \n",
    "    model, accuracy = fit_model(learning_rate=learning_rate,\n",
    "                                num_conv_layers=num_conv_layers,\n",
    "                                exp_num_filters=exp_num_filters,\n",
    "                                kernel_radius=kernel_radius,\n",
    "                                num_dense_layers=num_dense_layers,\n",
    "                                num_dense_nodes=num_dense_nodes,\n",
    "                                activation=activation)\n",
    "    \n",
    "    global best_run\n",
    "    \n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    \n",
    "    best_accuracy = max(runs['accuracy'] or [0.0])\n",
    "    if accuracy > best_accuracy:\n",
    "        print(\"Best Accuracy so far!\".format(best_accuracy))\n",
    "        model.save(MODEL_FILE_NAME)\n",
    "    else:\n",
    "        print(\"Best Accuracy so far: {0:.2%}\".format(best_accuracy))\n",
    "\n",
    "    print()\n",
    "\n",
    "    runs['accuracy'].append(accuracy)\n",
    "    runs['learning_rate'].append(learning_rate)\n",
    "    runs['num_conv_layers'].append(num_conv_layers)\n",
    "    runs['exp_num_filters'].append(exp_num_filters)\n",
    "    runs['num_dense_layers'].append(num_dense_layers)\n",
    "    runs['num_dense_nodes'].append(num_dense_nodes)\n",
    "    runs['activation'].append(activation)\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Scikit-optimize tries to find a set of hyper-parameters with the LOWEST fitness-value\n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = skopt.gp_minimize(func=fitness,\n",
    "                                  dimensions=dimensions,\n",
    "                                  acq_func='EI',\n",
    "                                  x0=initial_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(runs)\n",
    "df.sort_values('accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir './logs/fit/petimages'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!test_petimages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
